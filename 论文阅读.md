# 论文阅读
## Learning Dexterous In-Hand Manipulation

我们使用强化学习来学习灵巧的手持操作策略，这些策略可以在shadow灵巧手上执行基于视觉的对象重定向。 训练是在模拟环境中进行的，在该模拟环境中，我们**将系统的许多物理属性随机化**，如摩擦系数和物体外观。 尽管我们完全接受了模拟训练，但我们的政策仍转移到物理机器。我们的方法<u>不依赖于任何人类示范，但是在人类操纵中发现的许多行为自然地出现</u>，包括手指滑动，多指协调以及重力的受控使用。 我们的结果是使用用于训练OpenAI Five的相同分布式RL系统获得的[43]。

### Introduction

虽然对物体的灵巧操纵是人类的基本日常任务，但对自主机器人来说仍然具有挑战性。 <u>现代机器人通常设计用于受限设置中的特定任务，并且很大程度上无法利用复杂的末端效应器。</u> 相比之下，人们能够在各种环境中执行各种灵巧的操作任务，使人手成为机器人操纵研究的灵感源泉。

Shadow灵巧手[58]是为人类灵敏度设计的机器人手的一个例子; 它有五个手指，共有24个自由度。该手自2005年以来已经商业化;然而，它仍未被广泛采用，<u>这可归因于控制这种复杂系统的艰巨困难</u>。控制五指手的最先进技术受到严重限制。一些现有方法已经在模拟中显示了有希望的手动操作结果，但是没有尝试转移到现实世界的机器人[5,40]。相反，由于难以对这种复杂系统进行建模，因此还有一些仅在物理机器人上进行训练的方法[16,67,29,30]。然而，由于物理试验是如此缓慢且成本高昂，因此学习行为非常有限。

在这项工作中，我们演示了训练控制策略的方法，这些控制策略执行手动操作并将其部署在物理机器人上。 由此产生的政策表现出前所未有的灵巧性，并自然发现人类中的抓握类型，如三脚架，棱柱形和尖端捏抓，并显示接触丰富的动态行为，如手指滑动，多指协调，受控使用 重力，并协调应用平移和扭转力到物体。 我们的政策还可以使用视觉来感知物体的姿势 - 机器人的一个重要方面应该最终在受控制的实验室环境之外工作。

尽管完全在与现实世界大不相同的模拟器中进行训练，但我们获得了在物理机器人上表现良好的控制策略。我们将转移结果归因于**<u>（1）模拟环境中的广泛随机化和附加效应以及校准，（2）记忆增强控制策略，其允许在运行中学习自适应行为和隐式系统识别的可能性，以及（3）在大规模分布式强化学习。</u>**我们的方法概述如图2所示。

![屏幕快照 2018-09-26 下午7.56.26](/Users/lixiang/Desktop/屏幕快照 2018-09-26 下午7.56.26.png)

图2：系统概述。 （a）我们<u>使用具有随机参数和外观的大量模拟分布来收集控制策略和基于视觉的姿势估计器的数据。</u> （b）控制策略接收来自分布式模拟的观察到的机器人状态和奖励，并学习使用循环神经网络和强化学习将观察结果映射到动作。 （c）基于视觉的姿势估计器呈现从分布式模拟收集的场景并且学习使用与控制策略分开训练的卷积神经网络（CNN）从图像预测对象的姿势。 （d）为了转移到现实世界，我们使用<u>CNN预测来自3个真实摄像机馈送的物体姿势，使用3D运动捕捉系统测量机器人指尖位置，并将这两者用于控制策略以产生机器人的动作。</u>

该论文的结构如下。第2节给出了系统概述，更详细地描述了建议的任务，并显示了硬件设置。第3节描述了对控制策略，环境随机化以及添加到模拟器的附加效果的观察，这些效果使得传输成为可能。第4节概述了控制策略培训程序和分布式RL系统。第5节描述了视觉模型架构和培训程序。最后，第6节描述了在物理机器人上部署控制策略和视觉模型的定性和定量结果。